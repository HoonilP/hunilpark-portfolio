{
  "Home": {
    "title": "Hunil Park",
    "subtitle": "Frontend Developer",
    "description": "Crafting clean and refined web experiences",
    "comingSoon": "More sections coming soon"
  },
  "Navigation": {
    "home": "Home",
    "about": "About",
    "skills": "Skills",
    "projects": "Projects",
    "experience": "Experience",
    "education": "Education",
    "contact": "Contact"
  },
  "Common": {
    "language": "KO",
    "languageLabel": "Switch to Korean"
  },
  "Footer": {
    "email": "Email",
    "github": "GitHub",
    "velog": "Velog",
    "copyright": "Hunil Park. All rights reserved."
  },
  "Hero": {
    "name": "Hunil Park",
    "title": "Frontend Developer",
    "intro": "Crafting clean and refined web experiences",
    "resumeLink": "View Resume"
  },
  "About": {
    "sectionTitle": "About",
    "paragraph1": "I'm a frontend developer who designs and implements user-centric web interfaces. With hands-on experience building dashboards and management systems using React, Next.js, and TypeScript, I focus on translating complex business logic into intuitive UIs.",
    "paragraph2": "Having lived and worked in France, Myanmar, and Malaysia, I bring cross-cultural collaboration skills to every project. With strong English proficiency (TOEIC 930) and business-level French, I communicate effectively in global team settings."
  },
  "Contact": {
    "sectionTitle": "Contact",
    "description": "Interested in working together? Feel free to reach out.",
    "email": "Email",
    "phone": "Phone",
    "github": "GitHub",
    "velog": "Velog"
  },
  "Skills": {
    "sectionTitle": "Tech Stack",
    "frontend": "Frontend",
    "backend": "Backend",
    "devops": "DevOps",
    "database": "Database"
  },
  "Projects": {
    "sectionTitle": "Projects",
    "viewDetails": "View Details",
    "joshua": {
      "title": "Joshua AI Agent",
      "description": "AI copywriting agent powered by KoGPT-2. Built a cross-platform desktop app with Electron and Angular, integrated Stripe payments.",
      "period": "Jun 2022 - Mar 2023"
    },
    "dyCms": {
      "title": "DY Microfinance CMS",
      "description": "Customer management system built with Next.js and NestJS. Implemented an admin dashboard and automated ~90% of accounting processes.",
      "period": "Jul 2024 - Jun 2025"
    },
    "retailAnalysis": {
      "title": "Retail Store Customer Analysis",
      "description": "Visual intelligence system using YOLO for in-store customer tracking, with a VanillaJS dashboard for analytics visualization.",
      "period": "Nov 2022 - Apr 2023"
    },
    "scholarlyChain": {
      "title": "Scholarly Chain",
      "description": "Hyperledger Fabric blockchain-based student fee transparency system. Built 15+ pages with Next.js and shadcn/ui, implementing role-based UI and FCM push notifications.",
      "period": "Mar 2025 - Jun 2025"
    },
    "dinoGo": {
      "title": "Dino Go",
      "description": "Sui blockchain location-based NFT collection game. Built 3D maps with Next.js and Three.js, integrating Walrus decentralized storage and Seal encryption.",
      "period": "Sep 19-21, 2025"
    }
  },
  "Experience": {
    "sectionTitle": "Experience",
    "dyCms": {
      "date": "Jul 2024 - Jun 2025",
      "title": "DY Microfinance — CMS Development",
      "company": "DY Microfinance (Myanmar)",
      "description": "Developed a customer management system with a separated frontend-backend architecture using Next.js, NestJS, and PostgreSQL. Built an admin dashboard and automated ~90% of accounting processes."
    },
    "paymentInApp": {
      "date": "May 2022 - Mar 2024",
      "title": "Payment In-App Inc. — Business Planning Lead",
      "company": "Payment In-App Inc.",
      "description": "Led planning and execution of multiple projects including Joshua AI Agent (Electron/Angular), manufacturing defect detection (YOLO), retail customer behavior analysis (VanillaJS dashboard), and EMV Seoul transit feasibility study."
    },
    "dyAccounting": {
      "date": "Jan 2017 - Dec 2018",
      "title": "DY Microfinance — Accounting & Finance Operations",
      "company": "DY Microfinance (Myanmar)",
      "description": "Managed accounting and finance operations with process automation. Built automated BS/PL generation spreadsheets to improve operational efficiency."
    }
  },
  "Education": {
    "sectionTitle": "Education",
    "sangmyung": {
      "date": "Mar 2024 - Feb 2026",
      "title": "Sangmyung University, Dept. of Big Data Convergence",
      "description": "Expected Graduation | GPA 4.33 / 4.5"
    },
    "yangon": {
      "date": "Jan 2017 - Dec 2018",
      "title": "Yangon University of Foreign Languages, Myanmar Studies",
      "description": "Withdrawn"
    },
    "certificationsTitle": "Certifications & Awards",
    "certifications": {
      "computerSkills": "Computer Skills Level 1 (Nov 2020)",
      "accounting": "Computerized Accounting Level 1 (Mar 2021)",
      "fsi": "FSI AIxData Challenge 2024 Excellence Award",
      "toeic": "TOEIC 930 (Nov 2025)"
    },
    "activitiesTitle": "Activities",
    "activities": {
      "bay": "Yonsei University Blockchain Society BAY, 17th Cohort",
      "aiCourse": "Youngwoo Global Learning AI S/W Expert Training (Apr 2022)"
    }
  },
  "ProjectDetail": {
    "sidebar": {
      "role": "Role",
      "teamSize": "Team Size",
      "duration": "Duration",
      "techStack": "Tech Stack",
      "links": "Links"
    },
    "joshua": {
      "title": "Joshua AI Agent",
      "subtitle": "AI Copywriting Agent powered by KoGPT-2",
      "role": "Frontend Development",
      "teamSize": "4 members",
      "duration": "Jun 2022 - Mar 2023",
      "overview": {
        "title": "Project Overview",
        "background": "Joshua AI Agent is an AI-powered copywriting service built on the KoGPT-2 language model. It's a subscription-based desktop application that generates marketing content and advertising copy, supporting both Windows and macOS through a cross-platform architecture. The project required integrating a FastAPI backend with PostgreSQL database for AI model serving, where I was responsible for the frontend development. The key technical challenges included integrating Angular framework within Electron environment, implementing real-time streaming rendering of AI responses, and adapting the Stripe payment flow for desktop application context.",
        "contribution": "I led all aspects of frontend development, from designing the Electron + Angular desktop application architecture to implementing the AI response interface and Stripe payment integration. I designed the IPC (Inter-Process Communication) structure between Electron's Main and Renderer processes, handling backend API communication in the Main process while keeping the Angular-based Renderer process focused purely on UI rendering and user interaction. For progressive streaming display of AI-generated content, I built an asynchronous data processing pipeline using RxJS. I also customized Stripe's Checkout session-based payment flow to fit the desktop environment."
      },
      "implementation": {
        "title": "Technical Implementation",
        "feature1": {
          "title": "Electron + Angular Cross-Platform Desktop App Architecture",
          "problem": "Electron is typically paired with React or Vue, and integration examples with Angular were relatively scarce. I needed to harmoniously configure Angular's complex build setup (Webpack, TypeScript compiler) with Electron's Main/Renderer process structure, creating a build pipeline that worked reliably in both development and production environments. Setting up an HMR (Hot Module Replacement) environment that connects Angular's dev server with Electron processes was the core challenge.",
          "solution": "I built a build workflow using Electron Builder to package the Angular application into the Electron environment. The Main process was written in pure TypeScript to handle native functionality and system-level logic like BrowserWindow creation, IPC handler registration, and backend API communication. The Renderer process was configured to load the Angular CLI build output. In development mode, Electron loads the Angular dev server (localhost:4200), while in production builds it loads static files from the dist folder via file:// protocol. I designed IPC communication using ipcRenderer and ipcMain in a request-response pattern, maintaining a unidirectional data flow where user input from the Renderer triggers backend API calls through the Main process, with responses flowing back to the Renderer.",
          "result": "I successfully shipped a cross-platform desktop app that runs reliably on both Windows and macOS. In development, Angular's HMR enables fast development cycles, while production builds create single executable files (Windows: .exe, macOS: .dmg). The IPC communication layer allowed backend API changes to be isolated to the Main process, keeping coupling with Angular component code low."
        },
        "feature2": {
          "title": "Real-Time Streaming Rendering Interface for AI Responses",
          "problem": "The way we presented KoGPT-2 generated text to users was crucial. Displaying long copy all at once meant users received no feedback during wait time, degrading UX. Conversely, streaming the text token by token gave users a sense of 'generation in progress,' making perceived latency feel faster. When the backend sends responses via Server-Sent Events (SSE) or chunked format, the frontend needed to receive and render this data in real-time. I needed an efficient way to handle asynchronous stream data in Angular while smoothly updating the UI.",
          "solution": "I built an Observable-based asynchronous processing pipeline using RxJS. When the Main process receives streaming responses from the backend API via Electron IPC, it forwards each chunk as events to the Renderer process. Angular components subscribe to these events as Observables and reflect them on screen. Specifically, I used fetch API's ReadableStream to read backend responses, parsed each chunk, and transmitted it to the Renderer via ipcRenderer.send. In Angular components, I converted IPC events to Observables using fromEvent, accumulated text using the scan operator, and bound it to templates via async pipe. This created a natural typing animation effect.",
          "result": "Users could see the AI generating copy in real-time, making wait times feel subjectively shorter and improving the app experience. The RxJS-based architecture allowed me to declaratively add error handling (catchError), timeouts (timeout), and retry logic (retry), enabling the frontend to handle unstable backend APIs gracefully. User feedback highlighted positive reactions like 'seeing the generation process is great.'"
        },
        "feature3": {
          "title": "Stripe Payment Integration and Subscription Management UI",
          "problem": "As a subscription-based product, integrating Stripe Checkout payment flow and subscription status management UI was essential. Unlike typical web apps, desktop apps require opening a browser separately for payment, then returning to the app after completion. I needed to create a Stripe Checkout Session, have payment completed in an external browser, then have the app detect payment completion and update the UI accordingly. I also needed a dashboard interface to clearly show users whether they're currently subscribed, in a free trial, or if payment failed.",
          "solution": "I configured Stripe Checkout's web-based payment page to open in the default browser using Electron's shell.openExternal API. When the backend creates a Stripe Checkout Session, the client receives the URL and launches the browser where users enter card information on Stripe's secure payment page. After payment completion, the backend updates user subscription status via Stripe Webhook. The app polls the backend API periodically (or when users click a 'payment complete' button) to fetch the latest subscription status and refresh the UI. I managed subscription information in an Angular service layer using BehaviorSubject so subscription status could be referenced app-wide in real-time, displaying information like subscription expiration date and next payment date on the dashboard.",
          "result": "I was able to provide a secure, standard Stripe payment flow even in a desktop app environment. Users experienced a natural flow where clicking the payment button in the app opens a browser for payment completion, then returns to the app. The subscription status management UI helped users clearly understand their current subscription plan and remaining time, significantly reducing customer support inquiries. The combination of Stripe Webhook and polling ensured reliable handling of payment completion events without missing any."
        }
      },
      "troubleshooting": {
        "title": "Troubleshooting",
        "issue1": {
          "title": "Large Data Transfer Errors in Electron IPC Communication",
          "problem": "When transferring long AI-generated text or large amounts of history data from the Main process to the Renderer process via IPC, intermittent errors occurred. Transmitting data beyond a certain size caused Electron to throw memory errors or blocked the IPC channel, freezing the app. Initially, I tried sending all data at once using ipcRenderer.send and ipcMain.on, but this created bottlenecks during serialization for large data.",
          "solution": "I switched to a streaming approach, splitting large data into chunks for multiple transmissions. I transitioned to a Promise-based IPC pattern using ipcRenderer.invoke and ipcMain.handle, dividing data into fixed-size chunks (e.g., 1MB) for sequential transmission, then assembling them on the Renderer side. I also optimized backend response structure to avoid sending unnecessary data, adopting a GraphQL-style query approach on the frontend to selectively receive only needed fields.",
          "result": "The system became stable even when transferring large data, eliminating IPC communication bottlenecks and significantly improving app responsiveness. Users could query long histories or batch-generate large amounts of copy without the app freezing, maintaining smooth operation."
        },
        "issue2": {
          "title": "Angular Zone.js and Electron Event Loop Conflicts",
          "problem": "Angular uses Zone.js for automatic change detection, but when Electron IPC events occur outside Angular's Zone, UI doesn't automatically update. Specifically, changing component state in event listeners registered with ipcRenderer.on didn't reflect on screen, requiring users to manually navigate to another screen and back to see updates. This problem arose from developing without understanding Zone.js's operation principles.",
          "solution": "I injected the NgZone service and explicitly called zone.run() within IPC event handlers to enter Angular's change detection cycle. I encapsulated all IPC event reception logic in Angular services, converted them to Observables using fromEvent, and ensured execution within Angular Zone using observeOn(asyncScheduler). This guaranteed automatic UI updates when IPC events occurred.",
          "result": "IPC event-based state changes were immediately reflected on screen, greatly improving user experience. I gained deep understanding of Zone.js operation principles and established best practices for event handling in Electron + Angular environments."
        }
      },
      "retrospective": {
        "title": "Retrospective",
        "growth": "Developing a cross-platform desktop application combining Electron and Angular deepened my understanding of architecture for building native apps with web technology stacks. I learned a great deal solving unique problems that arise when combining web frameworks with desktop environments, including IPC communication structure design, Main/Renderer process role separation, and Angular Zone.js interaction with Electron's event loop. Experience with RxJS-based asynchronous data streaming proved valuable in subsequent projects. Stripe payment integration gave me capabilities for implementing SaaS business model frontends. Implementing an interface that renders AI model responses in real-time streaming made me realize the importance of UX design that transforms 'waiting' into 'experiencing' beyond simply displaying data.",
        "improvement": "Early in the project, I struggled with limited references for Electron-Angular integration through much trial and error. More thorough technical validation (POC) upfront would have accelerated development. Insufficient test code for the IPC communication layer consumed considerable debugging time—systematic unit and integration tests for Main-Renderer communication logic would have improved stability. From a performance optimization perspective, more thorough bundle size optimization (tree-shaking, lazy loading) and memory profiling could have improved app launch speed and resource usage. In future similar projects, I plan to clearly establish testing strategy and performance goals during initial design, with continuous monitoring and improvement."
      }
    },
    "dyCms": {
      "title": "DY Microfinance CMS",
      "subtitle": "Customer Management System",
      "role": "Full-stack Development",
      "teamSize": "1 member (Solo)",
      "duration": "Jul 2024 - Jun 2025",
      "overview": {
        "title": "Project Overview",
        "background": "DY Microfinance CMS is a web-based management system designed to automate customer management and accounting operations for a Myanmar-based microfinance institution. Previously, customer information, loan records, and accounting ledgers were managed manually using Excel spreadsheets, leading to frequent data integrity issues and requiring dozens of hours of manual work during month-end closing. To address this, I adopted a separated architecture connecting a Next.js frontend with a NestJS backend via PostgreSQL database. As a solo developer handling both frontend and backend, I focused on admin dashboard UI/UX design and implementation, complex accounting data table management, and form validation logic on the frontend side.",
        "contribution": "I was responsible for the entire process from system architecture design to deployment. From a frontend perspective, I implemented an admin dashboard based on Next.js App Router, form processing using Server Actions, accounting data table rendering optimization, and bilingual support (Burmese/English). The dashboard visualizes key metrics like customer count, loan balance, and monthly revenue in real-time, enabling management to grasp the current situation at a glance. Through accounting process automation, I built an interface that auto-generates BS (Balance Sheet) and PL (Profit & Loss) statements, eliminating approximately 90% of manual work and reducing month-end closing time from dozens of hours to just a few hours. I also implemented Role-Based Access Control at the frontend routing level, ensuring users (loan officers, accounting staff, administrators) can only access screens and features relevant to their roles."
      },
      "implementation": {
        "title": "Technical Implementation",
        "feature1": {
          "title": "Next.js-Based Admin Dashboard Design and Implementation",
          "problem": "Accounting staff and administrators needed to check numerous pieces of information daily. I had to intuitively display various data on a single screen—customer count, loan balance, delinquency rate, monthly revenue, recent loan applications—while ensuring page loading speed remained fast despite real-time data updates. PostgreSQL aggregate queries could be time-consuming, requiring a strategy for how the frontend fetches and displays data. Additionally, considering Myanmar users' unstable internet environment, offline support and data caching were important requirements.",
          "solution": "I leveraged Next.js App Router's Server Components to optimize initial loading speed by fetching data on the server and including it in the HTML before transmission. Core metrics (customer count, loan balance, etc.) are pre-calculated values provided by the backend API, with the frontend simply displaying them. Complex aggregations use PostgreSQL Materialized Views, periodically refreshed on the backend. For chart rendering, I used Recharts library to visualize monthly revenue trends and loan repayment rates. For table components, I used TanStack Table to handle sorting, filtering, and pagination quickly on the client side. I also introduced React Query (TanStack Query) to cache API responses, using a stale-while-revalidate strategy to show cached data first when users revisit the dashboard, fetching fresh data in the background.",
          "result": "Admin dashboard initial loading time was reduced to under 3 seconds, allowing users to immediately see key metrics upon opening the page. React Query's caching reduced unnecessary API calls even with frequent dashboard visits, decreasing server load. Charts and tables rendered smoothly, increasing user satisfaction. Even in unstable internet environments, basic information remained accessible via cached data."
        },
        "feature2": {
          "title": "Separated Frontend-Backend Architecture and API Integration",
          "problem": "Initially, I debated whether to develop as a full-stack setup using Next.js API Routes or completely separate frontend and backend. Considering the possibility of adding mobile apps or other clients in the future, separating the backend as an independent API server was advantageous, but managing two projects as a solo developer was burdensome. I also needed an architecture that maintains type safety when calling backend APIs from the frontend, and consistently handles authentication token management and error handling.",
          "solution": "I separated the Next.js frontend and NestJS backend, but used Next.js's rewrites feature in development to proxy /api/* paths to the NestJS server, avoiding CORS issues. In production, I used Nginx as a reverse proxy to serve frontend and backend from the same domain. I created a custom axios-based API client instance that automatically includes JWT tokens in all requests, with interceptors that automatically attempt token refresh on 401 responses. For type safety, I shared DTOs (Data Transfer Objects) defined in NestJS backend with the frontend, enabling compile-time validation of API request/response structures through TypeScript type inference. I added runtime type validation using Zod, immediately throwing errors when backend responses differ from expectations for easier debugging.",
          "result": "Frontend and backend were clearly separated, enabling independent development and deployment. The NestJS backend functions as a RESTful API server, making future mobile app or external system integration straightforward. The Next.js frontend could focus purely on UI/UX. The type-sharing structure meant backend API changes immediately triggered frontend type errors, preventing runtime errors proactively. Automatic token refresh via axios interceptors prevented session expiration even during extended dashboard use, improving user experience."
        },
        "feature3": {
          "title": "Accounting Process Automation Interface Implementation",
          "problem": "The existing accounting process involved manually entering loan records, repayment records, and expense data into Excel, then manually creating BS and PL statements at month-end. Automating this required providing forms on the frontend to input loan/repayment/expense data, performing accounting logic on the backend, then outputting results as reports on the frontend. Since accounting data integrity was critical, strict validation at the input stage was necessary, and UX-level guidance was needed to prevent users from entering incorrect data. Month-end reports also needed to be exportable as PDFs.",
          "solution": "I leveraged Next.js Server Actions to handle data validation and DB storage on the server side upon form submission. On the client side, I combined React Hook Form with Zod for real-time form validation, providing immediate feedback (error messages, success indicators) as users input fields. For example, loan amount fields accept only numbers, and repayment dates must be in the future relative to loan dates—validated on both client and server sides. For month-end report generation, when users click 'Generate Report,' the backend aggregates accounting data to create BS/PL statements. The frontend renders these as tables, then uses React-PDF library to convert to PDF on the client side for download. This simplified month-end closing to three steps: data input → button click → report download.",
          "result": "Accounting process automation reduced month-end closing time from dozens of hours to just a few, virtually eliminating manual errors (typos, calculation mistakes). Users received real-time error feedback during form input to correct invalid data beforehand. Instant PDF report generation for submission to management greatly improved work efficiency. Achieving approximately 90% automation dramatically reduced accounting staff workload and significantly improved data integrity."
        }
      },
      "troubleshooting": {
        "title": "Troubleshooting",
        "issue1": {
          "title": "Dashboard Table Rendering Performance Degradation",
          "problem": "As customer count grew to thousands, rendering the customer list table on the dashboard caused browser stuttering. Initially fetching all customer data from the backend at once for frontend rendering, thousands of rows took several seconds to draw in the DOM, with severe stuttering during scrolling. Users wanted to quickly scroll through tables to find specific customers, but rendering performance issues severely degraded usability.",
          "solution": "I introduced virtual scrolling techniques to optimize by rendering only rows visible in the current viewport to the DOM. Using TanStack Table's virtualization feature, even with thousands of data points, only 20-30 visible rows are actually rendered, with DOM dynamically replaced during scrolling. I also added server-side pagination as an optional feature, allowing users to fetch 50 items per page. I enhanced search filtering so users can filter by name or loan ID, fetching and rendering only matching data from the backend.",
          "result": "Table rendering performance improved dramatically, with initial loading completing in under 1 second even with thousands of customer records, and smooth scrolling. Users could quickly explore data, and virtual scrolling reduced memory usage, enabling stable operation even in low-spec environments."
        },
        "issue2": {
          "title": "Preventing Duplicate Form Submissions",
          "problem": "When users submitted loan application forms, clicking the button multiple times or slow network responses causing delays resulted in duplicate data being saved to the DB. In Myanmar's unstable internet environment, users frequently clicked the 'Submit' button again when nothing happened after the first click. This caused data integrity issues like the same loan application being created twice.",
          "solution": "On the frontend, I immediately disabled the submit button and displayed a loading indicator (spinner) upon form submission to clearly show users 'processing in progress.' Using React Hook Form's isSubmitting state, I prevented button clicks during submission. Upon Server Action completion, I displayed success or error messages for feedback. On the backend, I added idempotency handling with Redis-based duplicate request checking logic to process only the first request and ignore subsequent ones when identical requests arrive within a short time. I also applied the Optimistic UI pattern to update the UI immediately upon form submission, confirming after backend response for improved user experience.",
          "result": "Data integrity issues from duplicate requests were completely resolved. Users immediately received feedback after form submission, clearly recognizing 'processing in progress.' In slow network environments, users stopped clicking the button multiple times, reducing unnecessary requests and server load."
        }
      },
      "retrospective": {
        "title": "Retrospective",
        "growth": "As a solo full-stack developer designing and implementing both frontend and backend, I deepened my understanding of overall web application architecture. Particularly using Next.js App Router, Server Components, and Server Actions in production helped me experience the pros and cons of SSR and CSR firsthand, enabling me to judge which rendering strategy to choose in different situations. Configuring a separated frontend-backend architecture built practical skills essential for real-world work: API design, ensuring type safety, and handling authentication/authorization. Implementing dashboard and data visualization UI improved my UX design ability to translate complex business logic into user-friendly interfaces. Through accounting process automation, I experienced the value of development that creates 'business impact' beyond mere 'feature implementation,' finding great satisfaction in continuously improving based on user feedback.",
        "improvement": "Delaying test code writing early in the project led to occasional regression issues where new features broke existing ones. Especially for critical accuracy areas like accounting logic, unit and integration tests are essential—skipping them due to schedule pressure was regrettable. In the future, I want to adopt TDD (Test-Driven Development) or at least ensure test coverage for core business logic. CI/CD pipeline setup was also insufficient. Manual SSH deployment to servers could have been faster and more stable with automated deployment pipelines using GitHub Actions. For performance monitoring, introducing tools like Sentry or LogRocket to track production errors and performance bottlenecks in real-time would have enabled faster problem resolution. In my next project, I plan to establish testing, CI/CD, and monitoring from the start to build more stable and maintainable systems."
      }
    },
    "retailAnalysis": {
      "title": "Retail Store Customer Analysis",
      "subtitle": "Visual Intelligence-based Customer Tracking System",
      "role": "Data Visualization Development",
      "teamSize": "3 members",
      "duration": "Nov 2022 - Apr 2023",
      "overview": {
        "title": "Project Overview",
        "background": "A system deployed in retail stores in Malaysia that uses YOLO object detection models to track customer movement in real-time. It recognizes customer positions and movement paths from CCTV footage, collecting data on how long customers stay at which displays and what routes they take through the store. This enables store managers to understand customer behavior patterns and gain insights for optimizing display positioning and improving traffic flow. On the backend, a PyTorch-implemented YOLO model performs real-time video processing, while the frontend receives this data and visualizes it in dashboard form. For the frontend tech stack, VanillaJS (pure JavaScript) was deliberately chosen to validate whether complex real-time data visualization could be implemented without frameworks like React or Vue, and to optimize bundle size and performance.",
        "contribution": "I was responsible for all frontend data visualization aspects, building a real-time dashboard with VanillaJS. I implemented heatmap and movement tracking visualizations using Canvas API and SVG, receiving customer location data transmitted via WebSocket from the backend team. I displayed customers' current positions in real-time on the store floor plan, created heatmaps using color gradients to show customer density by time period, and connected individual customer movement paths with lines for tracking. I also implemented statistical charts (visitor count by time, dwell time by zone, etc.) using the Chart.js library. Since I had to perform state management and DOM manipulation without a framework, I designed simple state management patterns (Observer pattern) and component separation structure myself. I applied rendering optimizations (RequestAnimationFrame, Debouncing) to efficiently process incoming real-time data and implemented event listener cleanup logic to prevent memory leaks."
      },
      "implementation": {
        "title": "Technical Implementation",
        "feature1": {
          "title": "VanillaJS-Based Real-Time Data Visualization Dashboard",
          "problem": "I had to implement a complex real-time dashboard without frameworks like React or Vue. Without the convenience features frameworks provide—component structure, state management, virtual DOM—I needed to receive WebSocket data in pure JavaScript, render it in real-time to Canvas and SVG, and handle user interactions (zoom, pan, time filtering). Particularly when dozens of location data points arrive per second, directly manipulating the DOM could cause performance degradation, requiring efficient rendering strategies. I also needed to consider modularization and separation of concerns to prevent code from becoming spaghetti.",
          "solution": "I modularized code by functionality using ES6 Modules. I separated a DataService module for WebSocket communication, HeatmapRenderer module for Canvas rendering, PathRenderer module for SVG movement rendering, and ChartRenderer module for chart rendering. For state management, I implemented a simple Observer pattern where DataService sends notifications to registered renderers when receiving new data, prompting each to update. Canvas rendering used requestAnimationFrame to render in sync with browser repaint cycles for smooth animation, with conditions to redraw only when data changed to reduce unnecessary rendering. Heatmaps accumulated customer dwell time in 2D arrays, converted to color gradients and drawn on Canvas. SVG represented each customer's movement path as path elements, dynamically adding/removing them. User interactions (drag to move screen, mouse wheel to zoom) were handled by registering event listeners to manipulate Canvas transform.",
          "result": "I successfully implemented a stable, high-performance real-time dashboard without frameworks. Small bundle size (under 100KB excluding Chart.js) enabled very fast initial loading. Canvas-based rendering maintained 60fps even when simultaneously displaying hundreds of data points. Modularized code structure allowed independent development of new visualization features (e.g., displaying detailed information when clicking specific zones) without affecting other modules. Store managers could monitor customer movement in real-time and analyze time-based patterns to improve store layouts."
        },
        "feature2": {
          "title": "Canvas-Based Customer Movement Heatmap and Tracking UI",
          "problem": "I needed to intuitively represent customer movement on the store floor plan. With dozens of customers moving simultaneously, I needed visualization that displays each customer's position and movement path in real-time while allowing overall pattern understanding at a glance (which zones are popular, which routes are common). Heatmaps needed to express accumulated data over time with colors, while movement tracking needed to show individual customer paths with lines. Additionally, when users select time periods, only data from those periods should be filtered and displayed. Users also needed the ability to output month-end reports as PDFs.",
          "solution": "I used Canvas API to draw the store floor plan as background, then overlaid heatmap and movement layers. For heatmaps, I divided the store into a grid (e.g., 1m x 1m), accumulated customer dwell time in each grid cell, then expressed values with blue (low) → green (medium) → red (high) gradients. I used Canvas's fillRect and createLinearGradient for smooth color transitions. For movement tracking, I stored each customer's path in arrays and drew paths as lines using Canvas's lineTo and stroke. For time filtering, when users manipulate sliders, I filtered data to the selected time range and re-rendered heatmaps and movements. For performance with large datasets, I pre-calculated and cached all data, referencing cached data during filtering for quick rendering. I also added interaction where clicking specific zones displays detailed statistics (average dwell time, visitor count) in tooltips.",
          "result": "Store managers could visually understand 'which displays are most popular' and 'where blind spots customers rarely visit' through heatmaps. Movement tracking enabled analysis of 'what routes customers typically take from entrance' and 'whether paths to checkout are efficient.' Time filtering allowed comparison of time-based pattern differences like weekday mornings versus weekend evenings, informing adjustments to display positioning and promotion strategies. Canvas-based rendering performed smoothly without degradation even when simultaneously displaying hundreds of paths."
        }
      },
      "troubleshooting": {
        "title": "Troubleshooting",
        "issue1": {
          "title": "Memory Leaks During Real-Time Data Rendering",
          "problem": "Running the dashboard for extended periods caused browser memory usage to continuously increase, eventually slowing or crashing the browser. Initially, I continuously accumulated WebSocket incoming data in arrays and iterated through all data when rendering Canvas. Over time, array size grew, slowing rendering and consuming excessive memory. Event listeners not properly cleaned up also caused memory leaks.",
          "solution": "I modified data retention strategy to automatically delete data older than a certain time (e.g., 1 hour). I applied a Circular Buffer pattern to limit maximum data size, removing the oldest data when new data arrives. For rendering optimization, instead of redrawing all data every time, I introduced partial updates to redraw only changed portions. Event listeners were explicitly cleaned up by calling removeEventListener when components were removed (during page navigation). WebSocket connections were also terminated by calling close() when leaving the page. I used Chrome DevTools' Performance Monitor and Memory Profiler to find and fix memory leak points.",
          "result": "Memory leaks were resolved, enabling stable browser operation even when running the dashboard all day. Memory usage remained below a certain level, and rendering performance improved to maintain smooth animation during extended use. Store managers could keep the dashboard continuously running for real-time monitoring."
        },
        "issue2": {
          "title": "Increasing State Management Complexity in VanillaJS Environment",
          "problem": "Developing in pure JavaScript without frameworks caused increasingly complex state management. Multiple modules referencing and modifying the same data caused data synchronization issues, making it difficult to track which module changed data and hindering debugging. Particularly when users changed filters, multiple charts and heatmaps needed simultaneous updates. Manually calling each module made code complex and error-prone.",
          "solution": "I implemented a simple state management library myself. I created a central Store object based on the Observer pattern, where each module (renderers, charts) subscribes to the Store and receives automatic notifications when data changes. The Store manages state immutably, returning new objects on state changes, comparing with previous state to render only actually changed portions. State change logic was defined in an Actions object, structuring all state changes to occur through explicit actions. This implemented a Redux-like unidirectional data flow in VanillaJS. For debugging, I added middleware to log state change history to the console.",
          "result": "State management became clear and predictable. When data changes occurred, all subscribed modules automatically updated, eliminating the need to manually call each module. When bugs occurred, I could quickly identify causes by tracking state change history. When adding new features, I only needed to subscribe new modules without modifying existing code, greatly improving maintainability. I proved that complex state management is possible even with VanillaJS, but simultaneously experienced the value frameworks like React or Vue provide (component structure, virtual DOM, developer tools)."
        }
      },
      "retrospective": {
        "title": "Retrospective",
        "growth": "Implementing a complex real-time dashboard without frameworks using VanillaJS deepened my understanding of JavaScript's fundamental operation principles and browser rendering mechanisms. Directly handling Canvas API and SVG built low-level graphics rendering experience, strengthening crucial real-world frontend development capabilities like real-time data processing via WebSocket, memory management, and performance optimization. Particularly designing and implementing state management patterns myself helped me understand how state management libraries provided by React or Vue work internally, enabling deeper utilization when later using Redux or Vuex. Solving memory leak and rendering performance issues taught me profiling techniques using Chrome DevTools, and I gained valuable experience applying optimization patterns frequently used in practice like requestAnimationFrame, Debouncing, and Observer pattern. Through Canvas-based data visualization, I learned efficient methods for representing large datasets, which greatly helped when implementing charts or graphs in subsequent projects.",
        "improvement": "Developing with VanillaJS made me acutely feel the necessity of frameworks. Without convenience features modern frameworks provide—component reusability, declarative UI, virtual DOM—implementing everything manually was slow and created much code duplication. Particularly manually managing data synchronization across modules and DOM update logic was cumbersome and frequently caused bugs from mistakes. Had I used React, state management could have been simply handled with useState or useReducer, and Canvas rendering managed with useEffect for much more concise code. Also, component-based structure could have separated charts, heatmaps, and movements into independent components for improved reusability and testability. In the project's latter half, I thought 'React would have been right for this scale.' I realized VanillaJS is suitable for small-scale interactive elements or legacy system maintenance, but has limits for building complex SPAs. In future similar projects, I learned the importance of considering project scale and complexity when choosing technology to select appropriate frameworks. Next time, I want to build a better structured data visualization dashboard using a React + D3.js combination."
      }
    },
    "scholarlyChain": {
      "title": "Scholarly Chain",
      "subtitle": "Hyperledger Fabric Blockchain-based Student Fee Management System",
      "role": "Frontend Development (100%)",
      "teamSize": "4 members",
      "duration": "Mar 2025 - Jun 2025",
      "overview": {
        "title": "Project Overview",
        "background": "Scholarly Chain is a Hyperledger Fabric blockchain-based student fee transparency management system developed as a capstone design project. The goal was to record student fee revenue and expenditure on the blockchain to ensure transparency, allowing students to check fee usage in real-time. I was 100% responsible for the frontend built with Next.js, React, TypeScript, Tailwind CSS, and shadcn/ui, implementing role-based push notifications using Firebase Cloud Messaging and JWT-based authentication. The backend was integrated with a Hyperledger Fabric blockchain network, and the frontend called backend APIs to provide blockchain data to users.",
        "contribution": "In a 4-member team, I was solely responsible for all frontend development, creating over 15 pages and 30+ reusable components. I implemented a JWT automatic token refresh middleware to prevent user session disconnection, and designed a role-based UI system providing different dashboards and features for students, committee members, and administrators. Using the shadcn/ui component library, I built a consistent design system and integrated Firebase Cloud Messaging to implement a push notification system that selectively sends notifications (payment confirmation, expenditure approval, etc.) based on roles. I utilized Next.js API Routes as a proxy to relay backend API calls and deployed on Vercel to configure the actual service environment."
      },
      "implementation": {
        "title": "Technical Implementation",
        "feature1": {
          "title": "JWT Automatic Token Refresh Middleware",
          "problem": "When JWT access tokens expired while users were using the dashboard, API calls would fail and sessions would disconnect, requiring re-login. Especially when student council administrators reviewed expenditure records or performed approval tasks for extended periods, token expiration interruptions significantly degraded user experience. While access tokens should have short validity periods for security, requesting re-login from users every time was impractical. A mechanism to automatically refresh access tokens using refresh tokens was needed.",
          "solution": "I leveraged Next.js middleware functionality to intercept all API requests and check access token expiration. The middleware decodes and inspects JWT token expiration time, automatically using refresh tokens to obtain new access tokens when expiration is imminent or already passed. On successful refresh, new tokens are stored in cookies and the original request is retried, making the token refresh process transparent to users. If refresh tokens are also expired, users are redirected to the login page for re-authentication.",
          "result": "Users could maintain sessions automatically even during extended dashboard use, continuing work without interruption. The token refresh process handled automatically in the background greatly improved user experience, securing both security and convenience. Administrator feedback also noted positive reactions like 'convenient not to be logged out during work.'"
        },
        "feature2": {
          "title": "Role-based UI System",
          "problem": "The three roles—students, committee members, and administrators—each required different permissions and features. Students could only view student fee usage records, committee members could create expenditure requests, and administrators had expenditure approval and full data management authority. Rather than all users seeing the same screen, customized dashboards and menus needed to be provided based on roles. When users with insufficient permissions attempted to access pages, this needed to be blocked with appropriate feedback. While conditionally rendering different components by role, minimizing code duplication and maintaining maintainability was the challenge.",
          "solution": "I introduced the shadcn/ui component library to build a consistent design system and designed a structure that conditionally renders different UIs by role. Role information received from the backend during user authentication was stored in React Context, allowing all components to reference the current user's role. At the page level, I used Next.js middleware to implement role-based access control, redirecting unauthorized users attempting to access specific pages to a 403 error page. At the component level, I created a RoleBasedDashboard component that displays different dashboard layouts by role, configuring separate interfaces for students, committee members, and administrators. I reused shadcn/ui's Card, Table, Form and other components to reduce code duplication, and applied different theme colors by role using Tailwind CSS for visual distinction.",
          "result": "Users of each role clearly received only the features and information they needed, using the system without confusion. Thanks to shadcn/ui, role-based customization was easy while maintaining a consistent design system, and the existing structure could be utilized when adding new roles or permissions. User feedback noted evaluations like 'intuitive showing only the functions I need.'"
        },
        "feature3": {
          "title": "FCM Role-based Push Notification System",
          "problem": "When important events related to student fees occurred (payment confirmation, expenditure requests, expenditure approvals, etc.), users needed real-time notifications. However, sending all notifications to all users was unnecessary—only relevant notifications should be selectively sent based on roles. For example, when expenditure requests are submitted, only administrators should receive notifications, and when expenditures are approved, only the committee member who made the request should be notified. Push notifications needed to be implemented in a web environment, with interaction to navigate to relevant pages when users click notifications.",
          "solution": "I integrated Firebase Cloud Messaging (FCM) to implement web push notification functionality. When users log in, FCM tokens are issued and sent to the backend, which maps users' roles with FCM tokens and stores them in the database. When specific events occur on the backend, push notifications are sent via FCM API only to users of roles related to that event. On the frontend, I registered a Service Worker to receive push notifications even in the background, and implemented logic to automatically navigate to relevant pages (e.g., pending expenditure approval list) when notifications are clicked. I also user-friendly designed the notification permission request UI to guide notification settings during first login.",
          "result": "Users received real-time notifications of important events enabling immediate response, and role-based filtering reduced unnecessary notifications lowering notification fatigue. Administrators could immediately check and approve new expenditure requests, while committee members could know in real-time whether their requests were approved, greatly improving work efficiency. Push notifications via FCM became a core feature enhancing system responsiveness and user engagement."
        }
      },
      "troubleshooting": {
        "title": "Troubleshooting",
        "issue1": {
          "title": "Authentication Token Delivery Issues in API Route Proxy Pattern",
          "problem": "Rather than calling backend APIs directly from the frontend, I attempted to use Next.js API Routes as a proxy to avoid CORS issues and enhance security. However, when sending requests from the client to API Routes, JWT tokens stored in cookies needed to be passed along, and when API Routes sent requests to the backend, these tokens needed to be accurately delivered—but authentication failures frequently occurred due to tokens being dropped or improperly formatted during delivery. Especially reading tokens stored as httpOnly cookies on the server side and passing them to the backend was complex, and inconsistent error handling made debugging difficult.",
          "solution": "I created a standardized proxy function in API Routes that parses incoming request cookies to extract JWT tokens and delivers them in the Authorization header to the backend. All API Routes were structured to use this common proxy function, centralizing token delivery logic. When 401 or 403 responses came from the backend, the same status code and error message were returned to the client, enabling consistent error handling on the frontend. Additionally, since cookie settings (Secure, SameSite) needed to differ between development and production environments, I created a utility function that dynamically sets cookie options through environment variables.",
          "result": "The API Route proxy pattern stabilized, resolving authentication token delivery problems and enabling secure backend API calls without CORS issues. Thanks to the common proxy function, new API endpoints could be implemented consistently, and standardized error handling greatly reduced debugging time."
        },
        "issue2": {
          "title": "shadcn/ui Component Customization and Design System Consistency Maintenance",
          "problem": "shadcn/ui is a headless component library based on Radix UI where developers must handle styling themselves. While creating over 30 reusable components in the project, component styles were inconsistent and Tailwind CSS classes were duplicated making management difficult. Especially as basic components like Button, Card, and Form were customized differently across multiple pages, design system consistency broke down and maintenance became challenging. Additionally, dark mode support was needed, but manually specifying dark mode styles in every component was inefficient.",
          "solution": "I leveraged Tailwind CSS's @layer feature to define custom utility classes and created common style classes reusable in shadcn/ui components. For example, I created abstracted classes like btn-primary and card-base so all buttons and cards had the same basic styling. Design tokens like colors, spacing, and font sizes were predefined in Tailwind config file, with components styled by referencing tokens. Dark mode was configured to switch automatically using Tailwind's dark: prefix, and I implemented theme switching functionality with the next-themes library. I gathered the component library in the src/components/ui folder and documented each component's props and style options to provide guidance for consistent team usage.",
          "result": "Design system consistency greatly improved, and new pages or features could be developed quickly by reusing existing components. Thanks to Tailwind CSS utility classes, styling became concise and dark mode switching worked naturally improving user experience. Component documentation enabled smooth team collaboration, and when design modifications were needed, only centralized style classes needed updating, enhancing maintainability."
        }
      },
      "retrospective": {
        "title": "Retrospective",
        "growth": "Leading a large-scale frontend project using Next.js and shadcn/ui from start to finish greatly strengthened my practical capabilities with modern frontend development stacks. Implementing JWT authentication middleware and role-based access control gave me deep understanding of web application security and permission management, and building a push notification system through Firebase Cloud Messaging built real-time communication technology experience. Particularly as the sole frontend developer in a 4-member team creating over 15 pages and 30+ reusable components, the experience of independently designing and implementing a large-scale project greatly helped develop capabilities. Design system building experience using shadcn/ui and Tailwind CSS taught me how to maintain component reusability and consistency, and designing frontend-backend communication architecture through API Route proxy patterns also improved capabilities.",
        "improvement": "Not writing test code early in the project led to frequent regression bugs as features were added. Especially for complex logic like authentication or role-based UI where unit tests are essential, skipping them due to schedule pressure was regrettable. Next time I want to secure test coverage at least for core business logic to improve stability. Also, handling state management only with Context API caused prop drilling issues as component depth increased. Had I introduced a lightweight state management library like Zustand or Jotai, code would have been more concise and maintainable. Not sufficiently considering reusability during initial component design meant having to create similar components multiple times later. In the next project, I want to systematically design component structure from the design stage and consider testing and state management from the beginning to build a more robust system."
      }
    },
    "dinoGo": {
      "title": "Dino Go",
      "subtitle": "Sui Blockchain Location-based NFT Collection Game",
      "role": "Frontend Development",
      "teamSize": "4 members",
      "duration": "Sep 19-21, 2025 (Hackathon)",
      "overview": {
        "title": "Project Overview",
        "background": "Dino Go is a Sui blockchain-based location-based NFT collection game project conducted during a 3-day hackathon. It's a game where users collect virtual dinosaur NFTs by moving to actual locations and can trade collected NFTs on a marketplace. Google Maps API and Three.js were combined to implement a 3D map interface, NFT metadata is stored on Walrus decentralized storage, and data is protected with Seal threshold encryption. The frontend consists of Next.js, TypeScript, Three.js, and Tailwind CSS, while the backend comprises 4 Move smart contract modules and a Sui SDK-based Web3 communication layer.",
        "contribution": "In a 4-member team, I was responsible for the entire frontend, implementing over 10 pages including NFT Studio (minting interface), Marketplace UI, and 3D map interface. I integrated Google Maps API with Three.js to overlay 3D dinosaur characters and interactive elements on the map, implementing coordinate transformation logic so 3D objects render at accurate positions even when users drag or zoom the map. In NFT Studio, I provided a UI where users can mint NFTs and upload metadata to Walrus, while Marketplace implemented NFT list viewing, search, filtering, and trading features. I developed 3 custom Web3 client libraries integrating Sui SDK, Walrus, Seal, and Kiosk SDK to abstract communication with blockchain and decentralized storage on the frontend."
      },
      "implementation": {
        "title": "Technical Implementation",
        "feature1": {
          "title": "Google Maps + Three.js 3D Map Integration",
          "problem": "Google Maps API is optimized for 2D map rendering, while Three.js is a WebGL-based 3D graphics library. Combining the two libraries to overlay 3D dinosaur characters and interactive elements on Google Maps was technically challenging. Three.js's WebGL canvas needed to be precisely aligned with Google Maps' map tiles, and 3D objects needed to move synchronously when users dragged or zoomed the map. Additionally, mathematical calculations were needed to convert latitude/longitude coordinates to Three.js's 3D space coordinates, and performance optimization was essential for smooth rendering on mobile environments.",
          "solution": "I utilized Google Maps' OverlayView API to create a custom overlay and inserted Three.js's WebGLRenderer canvas within it. I overrode OverlayView's draw() method to update Three.js camera position and rotation whenever the map moved. Latitude/longitude coordinates were converted to pixel coordinates using Google Maps' Projection object, then mapped to Three.js's world coordinate system. 3D dinosaur models were loaded in glTF format and rendered at appropriate map positions based on each dinosaur's location information (latitude/longitude). For performance optimization, objects outside the viewport were culled to prevent rendering, and LOD (Level of Detail) techniques adjusted model detail based on distance.",
          "result": "3D dinosaur characters were naturally overlaid on Google Maps, enabling users to experience discovering virtual dinosaurs while exploring the actual map. Even when dragging or zooming the map, 3D objects rendered synchronously at accurate positions, and smooth frame rates above 30fps were maintained even on mobile environments. This unique UX received high evaluation as 'innovative user experience' during hackathon judging."
        },
        "feature2": {
          "title": "NFT Studio and Marketplace UI",
          "problem": "An interface was needed for users to mint and trade NFTs. The NFT minting process is complex—when users upload images, they must be stored on Walrus decentralized storage, metadata must be generated and recorded on the Sui blockchain. The Marketplace needed to view minted NFT lists, provide search and filtering features, and implement trading UI where users can buy or sell NFTs. Since blockchain transactions are asynchronous and time-consuming, providing clear progress status feedback to users was also important.",
          "solution": "In NFT Studio, I implemented multi-step forms using React Hook Form where users input NFT name, description, and image. Images are resized on the client side then uploaded via Walrus API, with returned hashes included in metadata. I used Sui SDK to call the Move smart contract's mint function to mint NFTs, displaying transaction progress status in real-time on the UI (Pending → Confirming → Success). Marketplace UI displayed NFT lists in a grid using TanStack Table, providing search bar and filters (price range, rarity, etc.). Clicking NFT cards opens a detail modal, and clicking the 'Buy' button creates a transaction via Kiosk SDK and sends it to the blockchain. After transaction completion, UI automatically refreshes to update user NFT ownership.",
          "result": "Users could easily mint and trade NFTs through intuitive UI. Thanks to Walrus decentralized storage, NFT images were safely stored, and ownership was transparently managed through metadata recorded on the blockchain. Marketplace search and filter features enabled users to quickly find desired NFTs, and real-time transaction status feedback greatly improved user experience. During hackathon demo, judges actually minted and traded NFTs, receiving evaluations of 'highly polished UI.'"
        },
        "feature3": {
          "title": "Web3 Client Library Development",
          "problem": "Using Sui SDK, Walrus, Seal, and Kiosk SDK directly on the frontend makes code complex, and blockchain communication logic mixed with UI components makes maintenance difficult. Each SDK has different usage methods, and inconsistent error handling and retry logic burden frontend developers with understanding all blockchain details. Additionally, identical blockchain call logic was duplicated across multiple pages, requiring multiple edits when changes occurred. Client libraries abstracting blockchain and decentralized storage communication were needed.",
          "solution": "I developed 3 custom client libraries wrapping Sui SDK, Walrus, and Seal respectively. SuiClient abstracts communication with Sui blockchain, providing high-level methods like mintNFT(), transferNFT(), getNFTsByOwner(). WalrusClient wraps file upload and download in a simple interface where calling uploadImage(file) automatically handles resizing, uploading, and hash return. SealClient provides functionality to encrypt and decrypt sensitive metadata using threshold encryption. Each client built in error handling and retry logic, configured to automatically retry on network failures. Written in TypeScript to ensure type safety, all methods unified as Promise-based asynchronous APIs.",
          "result": "Frontend components became much cleaner and more readable by simply calling client methods without directly handling blockchain logic. Centralized blockchain communication logic meant SDK version updates or error handling improvements only required client library modifications to automatically reflect across all pages. Type safety enabled catching errors at compile time, and team members could easily develop by just looking at client interfaces without knowing blockchain details. This abstraction enabled implementing stable Web3 features even within the short 3-day hackathon period."
        }
      },
      "troubleshooting": {
        "title": "Troubleshooting",
        "issue1": {
          "title": "Rendering Conflict Issues When Integrating Three.js with Google Maps",
          "problem": "When Google Maps' map tile rendering and Three.js's WebGL rendering executed simultaneously, the two renderers conflicted causing maps to flicker or 3D objects to disappear. Especially when users quickly dragged or zoomed maps, rendering frames got mixed frequently causing visual bugs. Since Google Maps' event loop and Three.js's rendering loop operated independently, synchronization was difficult and it wasn't clear when to update Three.js. Additionally, on mobile environments, performance degradation caused frame rates to drop sharply.",
          "solution": "I utilized Google Maps' idle event to update Three.js only after map movement completely stopped. This paused 3D rendering while users dragged maps, re-rendering 3D objects at final positions after dragging ended, preventing conflicts. I also used requestAnimationFrame to synchronize Three.js rendering loop with browser repaint cycles maintaining smooth animation. For mobile performance optimization, I reduced 3D model polygon counts, lowered texture resolutions, and applied frustum culling to not render objects outside the viewport. Adaptive quality settings that automatically adjust rendering quality based on device performance were also added.",
          "result": "Rendering conflict problems were resolved, enabling stable rendering of maps and 3D objects together. Even when users manipulated maps, smooth experiences without visual bugs were provided, and acceptable frame rates were maintained on mobile environments greatly improving usability. When tested on various devices during hackathon demo, all operated stably receiving positive evaluations from judges."
        }
      },
      "retrospective": {
        "title": "Retrospective",
        "growth": "Developing the entire frontend under extreme time constraints of a 3-day hackathon made me experience the importance of quick decision-making and priority setting. Through 3D graphics implementation using Three.js and Google Maps API integration experience, I could handle a unique tech stack combining WebGL rendering with map services, and gained blockchain frontend development capabilities by utilizing Web3 tech stacks (Sui SDK, Move, Walrus, Seal) in practice. Particularly while designing and implementing custom Web3 client libraries, I developed architecture design capabilities to create frontend developer-friendly interfaces by abstracting complex external SDKs. Through solving synchronization problems between two rendering systems during Google Maps and Three.js integration, I gained low-level rendering optimization and performance tuning experience. Completing features and demoing within hackathon's fast development pace was thanks to clear priority setting and smooth team collaboration.",
        "improvement": "Limited 3-day time forced compromising code quality. No test code was written at all, and error handling was implemented minimally leaving high bug possibility in edge cases. If developing into a production environment, thorough refactoring and securing test coverage are essential. Mobile optimization was also insufficient. Three.js rendering consumed much battery on mobile causing heating issues, but fundamental optimization wasn't done due to time shortage. Future work needs optimization like reducing WebGL rendering frequency or scaling back 3D effects on mobile. Much room for Three.js performance optimization remains. Applying advanced optimization techniques like model compression, texture atlases, and instancing could further improve performance. Hackathon experience made me clearly understand the difference between 'quickly making prototypes' and 'writing stable production code,' and in future projects I want to invest more time in initial design to build solid foundations."
      }
    }
  }
}
